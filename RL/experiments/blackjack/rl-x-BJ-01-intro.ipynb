{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e257397c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#OpenAI-gym-Blackjack-v0\" data-toc-modified-id=\"OpenAI-gym-Blackjack-v0-1\">OpenAI gym Blackjack-v0</a></span></li><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-2\"><em>Introducción</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-El-Entorno-Blackjack\" data-toc-modified-id=\"1.-El-Entorno-Blackjack-2.1\">1. El Entorno <em>Blackjack</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Descripción\" data-toc-modified-id=\"Descripción-2.1.1\">Descripción</a></span></li><li><span><a href=\"#Observaciones\" data-toc-modified-id=\"Observaciones-2.1.2\">Observaciones</a></span></li><li><span><a href=\"#Acciones\" data-toc-modified-id=\"Acciones-2.1.3\">Acciones</a></span></li><li><span><a href=\"#Recompensas\" data-toc-modified-id=\"Recompensas-2.1.4\">Recompensas</a></span></li></ul></li><li><span><a href=\"#2.-Probando-el-entorno-con-un-agente-humano\" data-toc-modified-id=\"2.-Probando-el-entorno-con-un-agente-humano-2.2\">2. Probando el entorno con un agente humano</a></span><ul class=\"toc-item\"><li><span><a href=\"#El-Agente:\" data-toc-modified-id=\"El-Agente:-2.2.1\">El Agente:</a></span></li><li><span><a href=\"#El-juego:\" data-toc-modified-id=\"El-juego:-2.2.2\">El juego:</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e99d53",
   "metadata": {},
   "source": [
    "## OpenAI gym Blackjack-v0 \n",
    "## _Introducción_\n",
    "---\n",
    "[Blackjack-v0 doc](https://gym.openai.com/envs/Blackjack-v0/)\n",
    "\n",
    "[Blackjack-v0 src](https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd224a",
   "metadata": {},
   "source": [
    "### 1. El Entorno _Blackjack_\n",
    "---\n",
    "#### Descripción\n",
    "El Blackjack es un juego de cartas donde el objetivo es obtener cartas que sumen una valor lo más próximo a 21 sin pasarse. En este entorno simulado de gym el agente (_jugador_) juega sólo contra el crupier (_dealer_).\n",
    "\n",
    "Se juega con la baraja inglesa. Para determinar el valor total de las cartas de los jugadores, se aplican las siguientes reglas:\n",
    "- Las cartas del 2 al 10 suman su valor numérico\n",
    "- Las cartas de figuras (J, Q, K) tienen valor 10\n",
    "- El as (1) puede sumar 1 ó 10, a elección del jugador\n",
    "- Se juega sin comodines\n",
    "\n",
    "Al empezar el juego, tanto el jugador como el crupier, reciben dos cartas. Las dos cartas del jugador están boca arriba por una sola del crupier.\n",
    "\n",
    "El jugador puede solicitar nuevas cartas (hit=1), una a una, hasta que decida plantarse (stick=0) o se pase de 21 (bust).\n",
    "\n",
    "Una vez que el jugador se planta, el crupier le dará la vuelta a su carta y sacará nuevas cartas hasta que su suma sea 17 o mayor. Si el crupier se pasa, gana el jugador.\n",
    "\n",
    "Si ninguno de los dos, jugador y crupier, se pasan, el resultado (win, lose, draw) se decide en función de quién se quedó más cerca de 21. \n",
    "\n",
    "<br>\n",
    "\n",
    "#### Observaciones\n",
    "Consiste en una tupla con tres valores: la suma actual del jugador, el valor de la carta vista del crupier, y si el jugador tiene o no un as.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Acciones\n",
    "El espacio discreto de acciones que puede tomar el agente es el siguiente:\n",
    "\n",
    "- 0: plantarse\n",
    "- 1: pedir carta\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Recompensas\n",
    "La recompensa por ganar es **+1**, por el empate es **0*+, y por perder es **-1**.\n",
    "\n",
    "<br>\n",
    "\n",
    "###### NOTA: \n",
    "Este entorno se corresponde con la versión del problema de blackjack descrito en el Ejemplo 5.1 del libro [Reinforcement Learning: An Introduction by Sutton and Burton](http://incompleteideas.net/book/the-book-2nd.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa314a",
   "metadata": {},
   "source": [
    "### 2. Probando el entorno con un agente humano\n",
    "---\n",
    "El siguiente código nos permite interactuar como juagador con el entorno Blackjack-v0 de gym.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### El Agente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b086ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BJConsoleHumanAgent():\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "        self._state = None\n",
    "        \n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._state\n",
    "    \n",
    "    @state.setter\n",
    "    def state(self, state):\n",
    "        self._state = state\n",
    "        \n",
    "    def action(self):\n",
    "        return int(input(\"action [stick=0 | hit=1]? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fcfaf0",
   "metadata": {},
   "source": [
    "#### El juego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c15bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats:\n",
      "------\n",
      "Total games: 1\n",
      "Total wins: 1\n",
      "Total losses: 0\n",
      "Total draws: 0\n",
      "Total reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from IPython.display import clear_output\n",
    "\n",
    "env = gym.make(\"Blackjack-v0\")\n",
    "agent = BJConsoleHumanAgent(env)\n",
    "\n",
    "total_games = 0\n",
    "total_reward = 0\n",
    "total_wins = 0\n",
    "total_losses = 0\n",
    "total_draws = 0\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    print(\"New Blackjack game...\")\n",
    "\n",
    "    agent.state = env.reset()\n",
    "    total_games += 1\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        print(\"\\nCurrent state:\", agent.state)\n",
    "        action = agent.action()\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        agent.state = new_state\n",
    "\n",
    "    print(\"\\nGame done...\")\n",
    "    print(\"Finale state:\", agent.state)\n",
    "    total_reward += reward\n",
    "    if reward == 1:\n",
    "        print(\"You win!!\")\n",
    "        total_wins += 1\n",
    "    elif reward == -1:\n",
    "        print(\"You lose!!\")\n",
    "        total_losses += 1\n",
    "    else:\n",
    "        print(\"Draw!!\")\n",
    "        total_draws += 1\n",
    "        \n",
    "    new = str()\n",
    "    while new not in('Y','N'):\n",
    "        new = input(\"New game [Y/N]? \").upper()\n",
    "    if new == 'N':\n",
    "        break\n",
    "\n",
    "# STATS\n",
    "clear_output(wait=True)\n",
    "print(\"\\nStats:\")\n",
    "print(\"------\")\n",
    "print(\"Total games:\", total_games)\n",
    "print(\"Total wins:\", total_wins)\n",
    "print(\"Total losses:\", total_losses)\n",
    "print(\"Total draws:\", total_draws)\n",
    "print(\"Total reward:\", total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
