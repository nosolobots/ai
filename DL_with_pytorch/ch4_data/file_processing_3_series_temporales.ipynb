{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de Ficheros III\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Series temporales\n",
    "---\n",
    "En el ejemplo precedente (calidad del vino), cada muestra (_sample_) o registro de la tabla era independiente de las otras.\n",
    "\n",
    "En nuestro siguiente ejemplo, vamos a lidiar con series de datos que tienen una componente temporal, lo que induce cierta ordenación en los datos de entrada.\n",
    "\n",
    "Para nuestra práctica, vamos a utilizar un _dataset_ de alquiler de bicicletas en la ciudad de Washington D.C. en los años 2011-2012. En dichos datos de entrada, cada fila se corresponde con una hora de datos. Nuestro objetivo será transformar ese _dataset_ 2D en uno 3D, donde uno de los ejes representará los días, otro represente la hora del día y, el tercer eje, las diferentes columnas de datos (tiempo, temperatura,...).\n",
    "\n",
    "<br>\n",
    "\n",
    "![](data/image-lect/bikeshare_dataset.png)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Loading the data\n",
    "---\n",
    "Los datos se encuentrán en un CSV, cuya primera fila contiene los nombres de las diferentes columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "bikes_path = \"data/tabular/hour-fixed.csv\"\n",
    "\n",
    "bikes_numpy = np.loadtxt(\n",
    "    bikes_path,\n",
    "    dtype=np.float32,\n",
    "    delimiter=\",\",\n",
    "    skiprows=1,\n",
    "    converters={1: lambda x: float(x[8:10])} # extrae sólo el día del mes del campo fecha\n",
    ")\n",
    "\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de las columnas de datos son los siguientes:\n",
    "\n",
    "- 'instant', índice del registro\n",
    "- 'dteday', días del mes\n",
    "- 'season', (1:primavera, 2:verano, 3:otoño, 4:invierno)\n",
    "- 'yr', año (2011, 2012)\n",
    "- 'mnth', mes \\[1, 12]\n",
    "- 'hr', hora \\[0, 23]\n",
    "- 'holiday', flag de vacaciones\n",
    "- 'weekday', día de la semana\n",
    "- 'workingday', flag de día laborable\n",
    "- 'weathersit', (1:despejado, 2:llovizna, 3:lluvia/nieve ligera, 4: lluvia/nieve fuerte)\n",
    "- 'temp', temp ºC\n",
    "- 'atemp', temp percibida ºC\n",
    "- 'hum', humedad\n",
    "- 'windspeed', velocidad del viento\n",
    "- 'casual', nº de usuarios casuales\n",
    "- 'registered', nº de usuarios registrados\n",
    "- 'cnt', total de alquileres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instant',\n",
       " 'dteday',\n",
       " 'season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'hr',\n",
       " 'holiday',\n",
       " 'weekday',\n",
       " 'workingday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " 'cnt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# column names\n",
    "col_list = next(csv.reader(open(bikes_path), delimiter=','))\n",
    "col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un _dataset_ de serie temporal como este, las filas representas _time-points_ sucesivos (están ordenadas por esa dimensión). La existencia de dicha ordenación nos brinda la oportunidad de explotar las relaciones temporales de los datos. Por ejemplo, nos permitiría predecir alquileres de bicicletas a una hora determinada basándonos en el hecho de que estaba lloviendo en las horas precedentes.\n",
    "\n",
    "Ahora nos encontramos con la tarea de preparar los datos para que puedan ser procesados convenientemente por la red neuronal. Ésta necesita ver una secuencia de valores para cada variable, como número de alquileres, hora, temperatura. Es decir, N secuencias paralelas de tamaño C (canales, que vendrían siendo los campos del registro). Nuestra dimensión N representará el eje del tiempo, una entrada por hora en este caso.\n",
    "\n",
    "Puede ser interesante reoordenar este _dataset_ de dos años en periodos de observación más amplios que una hora, como, por ejemplo, días. De esta forma, dispondremos de **N colecciones** de **C secuencias** de **longitud L**. La C se correspondería con nuestros 17 canales mientras que la longitud sería 24 (horas del día).\n",
    "\n",
    "Vamos a obtener una nueva vista de nuestro _dataset_ para organizarlo en _batches_ de 24 horas. Echemos un vistazo a nuestro tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17520, 17])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a obtener una nueva vista de nuestro tensor para tener 3 ejes: día, hora y, luego, las 17 columnas. Para ello, usaremos el método _view()_ que recibe como argumento las dimensiones (_shape_) que tendrá el nuevo tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La llamada al método _view()_ precedente recibe los siguientes argumentos: 730 (17520/24), 24 y 17. Para hacer la llamada al método de una forma más generalizada, pasamos directamente el tamaño de la dimensión 1 de bikes (17), fijamos la segunda dimensión a 24, y omitimos la primera de las dimensiones (empleando -1 como _placeholder_) de forma que PyTorch la tendrá que calcular automáticamente.\n",
    "\n",
    "Vemos como según el nuevo _stride_, avanzar un día de datos supone desplazarse 408 (24 horas x 17 campos) en la estructura interna, y avanzar una hora supone \"saltar\" los 17 campos de la hora actual hasta posicionarse en la siguiente.\n",
    "\n",
    "Finalmente, acabemos de reordenar nuestro tensor para que se ajuste al esquema deseado de: _N_x_C_x_L_. Esto podemos hacerlo de dos formas, empleando _transpose_ para hacer la transpuesta de las matrices internas (24 horas x 17 valores) o mediante _permute_ para intercambiar las dimensiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily_bikes = daily_bikes.transpose(1,2)\n",
    "daily_bikes = daily_bikes.permute(0,2,1)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Preparando el _dataset_ para el entrenamiento\n",
    "---\n",
    "La variable _\"weather situation\"_ es ordinal. Tiene cuatro posibles valores, desde **1** (buen tiempo) a **4** (mal tiempo). \n",
    "\n",
    "Por otro lado, podemos tratarla también como nominal o categórica. En este último caso, podríamos codificarla en un vector _one-hot_ y concatenar las nuevas columnas con el _dataset_.\n",
    "\n",
    "Para simplificar nuestro experimento, vamos a limitarnos por el momento al primer día del _dataset_. Inicializaremos a zero una matriz con tantas filas como horas hay en el día (24) y tantas columnas como posibles situaciones contempladas del tiempo (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "first_day[:, 9] # weathersit column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, deberemos rellenar nuestra matriz _one-hot_ a partir de esa columna de valores. Para ello, deberemos añadir una nueva dimensión al tensor con los datos del primer día para que ambos tensores tengan el mismo número de dimensiones (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot.scatter_(\n",
    "    dim=1, # dimension de la lista de valores que vamos a procesar\n",
    "    index=first_day[:,9].unsqueeze(1).long() - 1, # valores - 1\n",
    "    value=1.0 # valor que se insertará en cada posición \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, concatenaremos este nuevo tensor al tensor _first_\\__day_ empleando la función _cat()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   0.,   1.,   0.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   3.,  13.,  16.,   1.,   0.,   0.,   0.],\n",
       "        [  2.,   1.,   1.,   0.,   1.,   1.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   8.,  32.,  40.,   1.,   0.,   0.,   0.],\n",
       "        [  3.,   1.,   1.,   0.,   1.,   2.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   5.,  27.,  32.,   1.,   0.,   0.,   0.],\n",
       "        [  4.,   1.,   1.,   0.,   1.,   3.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   3.,  10.,  13.,   1.,   0.,   0.,   0.],\n",
       "        [  5.,   1.,   1.,   0.,   1.,   4.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   0.,   1.,   1.,   1.,   0.,   0.,   0.],\n",
       "        [  6.,   1.,   1.,   0.,   1.,   5.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,   0.,   1.,   1.,   0.,   1.,   0.,   0.],\n",
       "        [  7.,   1.,   1.,   0.,   1.,   6.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   2.,   0.,   2.,   1.,   0.,   0.,   0.],\n",
       "        [  8.,   1.,   1.,   0.,   1.,   7.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   1.,   2.,   3.,   1.,   0.,   0.,   0.],\n",
       "        [  9.,   1.,   1.,   0.,   1.,   8.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   1.,   7.,   8.,   1.,   0.,   0.,   0.],\n",
       "        [ 10.,   1.,   1.,   0.,   1.,   9.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   8.,   6.,  14.,   1.,   0.,   0.,   0.],\n",
       "        [ 11.,   1.,   1.,   0.,   1.,  10.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,  12.,  24.,  36.,   1.,   0.,   0.,   0.],\n",
       "        [ 12.,   1.,   1.,   0.,   1.,  11.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,  26.,  30.,  56.,   1.,   0.,   0.,   0.],\n",
       "        [ 13.,   1.,   1.,   0.,   1.,  12.,   0.,   6.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,  29.,  55.,  84.,   1.,   0.,   0.,   0.],\n",
       "        [ 14.,   1.,   1.,   0.,   1.,  13.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  47.,  47.,  94.,   0.,   1.,   0.,   0.],\n",
       "        [ 15.,   1.,   1.,   0.,   1.,  14.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  35.,  71., 106.,   0.,   1.,   0.,   0.],\n",
       "        [ 16.,   1.,   1.,   0.,   1.,  15.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  40.,  70., 110.,   0.,   1.,   0.,   0.],\n",
       "        [ 17.,   1.,   1.,   0.,   1.,  16.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  41.,  52.,  93.,   0.,   1.,   0.,   0.],\n",
       "        [ 18.,   1.,   1.,   0.,   1.,  17.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  15.,  52.,  67.,   0.,   1.,   0.,   0.],\n",
       "        [ 19.,   1.,   1.,   0.,   1.,  18.,   0.,   6.,   0.,   3.,   0.,   0.,\n",
       "           0.,   0.,   9.,  26.,  35.,   0.,   0.,   1.,   0.],\n",
       "        [ 20.,   1.,   1.,   0.,   1.,  19.,   0.,   6.,   0.,   3.,   0.,   0.,\n",
       "           0.,   0.,   6.,  31.,  37.,   0.,   0.,   1.,   0.],\n",
       "        [ 21.,   1.,   1.,   0.,   1.,  20.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  11.,  25.,  36.,   0.,   1.,   0.,   0.],\n",
       "        [ 22.,   1.,   1.,   0.,   1.,  21.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,   3.,  31.,  34.,   0.,   1.,   0.,   0.],\n",
       "        [ 23.,   1.,   1.,   0.,   1.,  22.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  11.,  17.,  28.,   0.,   1.,   0.,   0.],\n",
       "        [ 24.,   1.,   1.,   0.,   1.,  23.,   0.,   6.,   0.,   2.,   0.,   0.,\n",
       "           0.,   0.,  15.,  24.,  39.,   0.,   1.,   0.,   0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((first_day, weather_onehot), 1) # concatena las columnas, la segunda dimension (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras nuestro pequeño experimento, vamos a hacer los mismo para todo el _dataset_ (daily_bikes). Recuerda que lo \"remapeamos\" como _NxCxL_, donde N representa cada uno de los días (730 = 2 años x 365 d), C son las variables (17) y L son las horas (24). \n",
    "\n",
    "Primero, crearemos un tensor del mismo N y L, pero de 4 canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos el \"scatter\" de la columna \"weathersit\" sobre el nuevo tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y concatenamos a lo largo de la dimensión C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 25, 24])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)\n",
    "daily_bikes.shape # la segunda dimensiónse incrementará en 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
