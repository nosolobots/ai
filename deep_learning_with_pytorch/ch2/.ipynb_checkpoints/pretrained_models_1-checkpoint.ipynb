{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA preentrenadas\n",
    "## (_reconocimiento de imágenes_)\n",
    "___\n",
    "\n",
    "Existen numerosas redes neuronales artificiales (RNA ó _Artificial Neural Networks, ANN_) ya configuradas y entrenadas para distintas tareas como, por ejemplo, el reconocimiento de imágenes.\n",
    "\n",
    "\n",
    "Es habitual que los investigadores publiquen, junto con sus trabajos, el código fuente y los parámetros (_pesos_) obtenidos durante el entrenamiento del modelo a partir de un conjunto de datos de referencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RN preentrenadas en pyTorch\n",
    "---\n",
    "El módulo **torchvision.models** contiene diversos modelos predefinidos\n",
    "\n",
    "\n",
    "Los nombres en mayúsculas son clases Python que implementan dichos modelos\n",
    "\n",
    "\n",
    "Los nombres en minúsculas son funciones que devuelven modelos instanciados a partir de dichas clases, en ocasiones con diferentes conjuntos de parámetros. Por ejemplo, _resnet101_ devuelve una instancia de *ResNet* con 101 capas, mientras que *resnet18* tiene 18 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "dir(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "___\n",
    "El modelo *AlexNet* ganó la competición [ILSVRC](http://www.image-net.org/challenges/LSVRC/) (_ImageNet Large Scale Visual Recognition Challenge_) de 2012, \"barriendo\" a sus competidores. \n",
    "\n",
    "En esta competición se evalúan algoritmos para la detección de objetos y la clasificación de imágenes. En concreto, el conjunto de datos (_dataset_) para la clasificación de imágenes según su contenido está formado por **1.2 millones** de imágenes etiquetadas con uno de entre **1.000 nombres** (por ejemplo: \"gato\")\n",
    "\n",
    "*AlexNet*, que se basa en el empleo de redes neuronales convolucionales (CNN) entrenadas sobre GPU, es considerado uno de los trabajos más influyentes en la visión por computadora. \n",
    "\n",
    "Para ejecutar el modelo _AlexNet_ en una imagen de entrada, podemos instanciar un objeto de la clase correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.AlexNet()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que acabamos de obtener es un objeto que replica la arquitectura de la red neuronal _AlexNet_. Sin embargo, esta red está \"sin entrenar\". Necesitaríamos un conjunto de imágenes de prueba, convenientemente etiquetadas, para que pueda \"autoajustar\" sus parámetros. Una vez entrenada, ya podríamos usar nuestra red para clasificar imágenes.\n",
    "\n",
    "Las funciones proporcionadas por el módulo **torchvision.modules** nos permiten instanciar modelos ya preentrenados, es decir, con sus pesos internos ajustados. Veamos como."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificando imágenes con ResNet\n",
    "___\n",
    "El modelo _ResNet_ ganó varios de los concursosde la competición ILSVRC en 2015. Su arquitectura se basa en estructuras conocidas de células piramidales del cortex cerebral y supuso el inicio del desarrollo de redes neuronales convolucionales extremadamente profundas (_AlexNet_ tenía 8 capas frente a las 101 que genera _resnet101_)\n",
    "\n",
    "Vamos a crear una instancia de _ResNet_ pero de forma que \"venga\" ya entrenada. En este caso, a partir del _dataset_ de **ImageNet** de 1.2 millones de imágenes y 1.000 categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a la estructura de nuestra ANN. Ésta está formada por numerosas capas (_layers_), cada una de ellas compuesta por múltiples unidades funcionales (_neuronas_), conectadas entre sí para la realización de diferentes operaciones. Finalmente, esta secuencia en cascada de filtros y operaciones no lineales, terminará en una capa final donde se generarán las puntuaciones (probabilidades) para cada una de las clases de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificando imágenes\n",
    "---\n",
    "Nuestra nueva red, referenciada por la variable _resnet_, puede ser invocada como una función, recibiendo como argumento una imagen y devolviendo, como resultado, qué es lo que la red neuronal acierta a \"ver\" en ella. En realidad, nos devolverá un vector con la probabilidades de que, lo que aperece en la imagen, sea cada una de las 1.000 palabras (_etiquetas_) con las que fue entrenada para clasificar imágenes.\n",
    "\n",
    "Antes de que podamos hacer esto, necesitamos preprocesar nuestra imagen de entrada para ajustar su tamaño y rangos de los colores de los píxeles a los del set de entrenamiento. Para ello, el módulo **torchvision** nos proporciona las herramientas necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos definido una función (_preprocess_) que \"ejecutará\" una serie de acciones (_Compose_) sobre nuestras imágenes: la escalará a 256x256, la recortará a 224x224 alrededor del centro, la convertirá en un tensor de PyTorch (en este caso, un vector de 3 dimensiones: alto, ancho y color RGB) y, finalmente, normalizará sus componentes RGB a los valores de media (_mean_) y desviación estándar (_std_) del _dataset_ de entrenamiento.\n",
    "\n",
    "Ahora es el momento de coger una de nuestras fotos favoritas, preprocesarla, y ver que nos dice RasNet de ella.\n",
    "\n",
    "Para nuestro ejemplo, vamos a usar una foto de la mítica gata _Grumpy Cat_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"grumpy_cat.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargada la imagen, vamos a preprocesarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = preprocess(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos listos para \"evaluar\" la imagen con nuestra ANN. Para ello, necesitamos poner nuestro modelo en modo _eval_. A continuación le pasaremos la imagen de entrada, obteniendo como resultado un vector de probabilidades para cada una de las 1.000 clases definidas en el _dataset_ de _ImageNet_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "out = resnet(batch_t)\n",
    "print(\"probs:\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos ahora encontrar la etiqueta de la clase que recibió la puntuación (probabilidad) más alta. Para ello, cargaremos una lista con las etiquetas con el mismo orden en que fue entrenada la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, determinaremos el índice correspondiente a la entrada con la puntuación máxima y extraeremos la etiqueta de la lista anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(out, 1)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0]*100\n",
    "print(labels[index[0]], percentage[index[0]].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra red neuronal nos dice que es un _Gato Siamés_ con un probabilidad de un 55.34%\n",
    "\n",
    "No parece una probabilidad demasiado alta! Vamos a ver que otras opciones consideraba..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.sort(out, descending=True)\n",
    "for idx in indices[0][:5]:\n",
    "    print(labels[idx], percentage[idx].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, dudaba entre varias razas de gato (siamés, persa,...)\n",
    "\n",
    "Vamos a ponérselo ahora un poco más difícil con esta imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = Image.open(\"devon_dog.jpg\")\n",
    "img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamos la imagen y la pasamos por la red neuronal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesado\n",
    "img_t = preprocess(img2)\n",
    "batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "# clasificación\n",
    "out = resnet(batch_t)\n",
    "\n",
    "# resultados\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0]*100\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "for idx in indices[0][:5]:\n",
    "    print(labels[idx], percentage[idx].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, lo relevante para la red en este caso son las gafas de sol, y clasifica la imagen como tal. \n",
    "\n",
    "Y tú? cómo clasificarías esta imagen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it!\n",
    "___\n",
    "\n",
    "Modifica el siguiente código con la URL de la imagen que quieres que analice nuestra red neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Introduce la URL aquí\n",
    "URL = 'https://www.tegustaviajar.com/wp-content/uploads/2019/03/castillo-de-la-mota.jpg'\n",
    "# -------------------------------------------------\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "\n",
    "img_try = Image.open(f)\n",
    "img_try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora ejecuta la siguiente celda (parte del código anterior se ha agrupado en la función **guess_what()**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def guess_what(img, resnet, labels, nres):\n",
    "    \"\"\"Procesa la imagen y muestra los resultados más probables\n",
    "    \n",
    "    Args:\n",
    "        img: imagen a procesar\n",
    "        resnet: CNN resnet previamente entrenada\n",
    "        labels: colección de eiquetas para clasificar las imágenes\n",
    "        nres: número de resultados\n",
    "    \"\"\"\n",
    "    # preprocesado -----------------------------------------\n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    # clasificación ----------------------------------------\n",
    "    out = resnet(batch_t)\n",
    "\n",
    "    # muestra resultados -----------------------------------\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0]*100\n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "\n",
    "    for idx in indices[0][:nres]:\n",
    "        print(labels[idx], percentage[idx].item())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Llamamos a la función aquí\n",
    "# El último parámetro indica cuántos resultados quieres\n",
    "guess_what(img_try, resnet, labels, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
