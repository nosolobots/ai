{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Fashion MNIST with Convolutions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a reescribir nuestro modelo para Fashion-MNIST para intentar mejorar su rendimiento añadiéndole capas de convolución\n",
    "<br><br>\n",
    "Para ello, añadiremos las siguientes capas:\n",
    "<br><br>\n",
    "**Conv2D**: procesará bloques de 3x3 píxels (por cada píxel, tiene en cuenta los 8 píxeles que los rodean) y aplicará 64 filtros (convoluciones) diferentes. \n",
    "<br><br>\n",
    "**MaxPooling**: comprime los datos quedándose con el máximo de cada bloque de 2x2 píxels, reduciendo por tanto la imagen a la mitad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Convoluciones\n",
    "Las convoluciones actúan como filtros sobre la imagen (por ejemplo, realzado o detección de bordes). Por cada imagen del train set, se generarán nuevas imágenes (una por fltro) con lo que la red neuronal dispondrá de información adicional para su aprendizaje.\n",
    "\n",
    "A modo de ejemplo, vamos a ver como actuaría uno de estos filtros implementado manualmente sobre una de las imágenes del train set. El filtro a implementar nos permitirá detectar bordes en la imagen. Para ello, aplicará la siguiente máscara de 3x3 por cada píxel de la imagen:\n",
    "\n",
    "```\n",
    "-1 -1 -1\n",
    "-1  8 -1\n",
    "-1 -1 -1\n",
    "```\n",
    "Es decir, por cada píxel, obtendrá un nuevo valor resultante de multiplicar su valor actual por 8 y restar el valor de los píxeles vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"tensorboard/compat/proto/resource_handle.proto\":\n  tensorboard.ResourceHandleProto.device: \"tensorboard.ResourceHandleProto.device\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.container: \"tensorboard.ResourceHandleProto.container\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.name: \"tensorboard.ResourceHandleProto.name\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.hash_code: \"tensorboard.ResourceHandleProto.hash_code\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.maybe_type_name: \"tensorboard.ResourceHandleProto.maybe_type_name\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto: \"tensorboard.ResourceHandleProto\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-44ef3cbbc8c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/_api/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/_api/v1/compat/v2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0m_current_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m   _current_module.__path__ = (\n\u001b[1;32m    305\u001b[0m       [_module_util.get_parent_dir(summary)] + _current_module.__path__)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \"\"\"\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevent_file_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventFileWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sprite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_tsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_pbtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/summary/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# If the V1 summary API is accessible, load and re-export it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/summary/v1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_audio_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_scalar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_custom_scalar_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_histogram_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/plugins/audio/summary.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mencoder_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/plugins/audio/metadata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplugin_data_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtb_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/compat/proto/summary_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/compat/proto/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorboard/compat/proto/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0msyntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'proto3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mserialized_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\030org.tensorflow.frameworkB\\016ResourceHandleP\\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\370\\001\\001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mserialized_pb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n.tensorboard/compat/proto/resource_handle.proto\\x12\\x0btensorboard\\\"r\\n\\x13ResourceHandleProto\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\tcontainer\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x11\\n\\thash_code\\x18\\x04 \\x01(\\x04\\x12\\x17\\n\\x0fmaybe_type_name\\x18\\x05 \\x01(\\tBn\\n\\x18org.tensorflow.frameworkB\\x0eResourceHandleP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[1;32m    939\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please link in cpp generated lib for %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mserialized_pb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddSerializedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_pb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileDescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"tensorboard/compat/proto/resource_handle.proto\":\n  tensorboard.ResourceHandleProto.device: \"tensorboard.ResourceHandleProto.device\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.container: \"tensorboard.ResourceHandleProto.container\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.name: \"tensorboard.ResourceHandleProto.name\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.hash_code: \"tensorboard.ResourceHandleProto.hash_code\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto.maybe_type_name: \"tensorboard.ResourceHandleProto.maybe_type_name\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n  tensorboard.ResourceHandleProto: \"tensorboard.ResourceHandleProto\" is already defined in file \"tensorboard/src/resource_handle.proto\".\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def edge_filter(img):\n",
    "    # init filtered image\n",
    "    new_img = np.zeros(img.shape)\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # loops boundaries around pixel\n",
    "            fval = 0.0\n",
    "            r_ini = i-1\n",
    "            if r_ini<0: r_ini=0\n",
    "            r_end = i+1\n",
    "            if r_end==img.shape[0]: r_end -= 1\n",
    "            c_ini = j-1\n",
    "            if c_ini<0: c_ini=0\n",
    "            c_end = j+1\n",
    "            if c_end==img.shape[1]: c_end -= 1\n",
    "            # compute new pixel value\n",
    "            for r in range(r_ini, r_end+1):\n",
    "                for c in range(c_ini, c_end+1):\n",
    "                    if r==i and c==j:\n",
    "                        fval += 8*img[r][c]\n",
    "                    else:\n",
    "                        fval -= img[r][c]\n",
    "            \n",
    "            # constrain max, min values\n",
    "            #if fval<0: fval=0\n",
    "            #if fval>255: fval=255\n",
    "            \n",
    "            # update filtered image\n",
    "            new_img[i][j] = fval\n",
    "            \n",
    "    # map resulted pixel values in the range [0, 255]\n",
    "    new_img = np.interp(new_img, (new_img.min(), new_img.max()), (0,255)) \n",
    "    \n",
    "    # round to int\n",
    "    new_img = np.rint(new_img)\n",
    "    # convert to int type\n",
    "    new_img = new_img.astype(int)\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "def pooling_filter(img):\n",
    "    size_x = img.shape[1]\n",
    "    size_y = img.shape[0]\n",
    "    \n",
    "    # init filtered image\n",
    "    new_y = int(size_y/2)\n",
    "    new_x = int(size_x/2)\n",
    "    new_img = np.zeros((new_y, new_x))\n",
    "    for x in range(0, size_x, 2):\n",
    "        for y in range(0, size_y, 2):\n",
    "            max_val = 0\n",
    "            if img[x][y]>max_val: max_val=img[x][y]\n",
    "            if img[x+1][y]>max_val: max_val=img[x+1][y]\n",
    "            if img[x][y+1]>max_val: max_val=img[x][y+1]\n",
    "            if img[x+1][y+1]>max_val: max_val=img[x+1][y+1]\n",
    "            new_img[int(x/2)][int(y/2)] = max_val\n",
    "    return new_img\n",
    "\n",
    "# load data\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(train_data, train_labels), (test_data, test_labels) = fmnist.load_data()\n",
    "\n",
    "# select randomly an image from the dataset\n",
    "index = np.random.randint(0, train_data.shape[0]+1)\n",
    "image = train_data[index]\n",
    "\n",
    "# create a filtered image\n",
    "fimage = edge_filter(image)\n",
    "\n",
    "# create a max pooled image from previous\n",
    "pimage = pooling_filter(fimage)\n",
    "\n",
    "# show image values and pictures\n",
    "np.set_printoptions(linewidth=200)\n",
    "\n",
    "fig, axis = plt.subplots(1, 3, figsize=(6, 2.25), gridspec_kw={'width_ratios': [2,2,1]})\n",
    "axis[0].imshow(train_data[index], cmap=\"gray_r\")\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(fimage, cmap=\"gray_r\")\n",
    "axis[1].axis(\"off\")\n",
    "axis[2].imshow(pimage, cmap=\"gray_r\")\n",
    "axis[2].axis(\"off\")\n",
    "\n",
    "\n",
    "print(train_data[index])\n",
    "print(fimage)\n",
    "print(pimage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Aplicando convoluciones al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 449,994\n",
      "Trainable params: 449,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4332 - acc: 0.8417\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2882 - acc: 0.8941\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2428 - acc: 0.9097\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2065 - acc: 0.9227\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.1792 - acc: 0.9325\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.1567 - acc: 0.9413\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.1358 - acc: 0.9492\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1136 - acc: 0.9572\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0975 - acc: 0.9627\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0833 - acc: 0.9688\n",
      "10000/10000 [==============================] - 1s 82us/sample - loss: 0.3278 - acc: 0.9126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32780218888521195, 0.9126]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, loss=0.0, acc=0.0):\n",
    "        self.loss = loss\n",
    "        self.acc = acc\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.loss>0.0 and logs.get('loss')<self.loss:\n",
    "            self.model.stop_training = True\n",
    "        elif self.acc>0.0 and logs.get('acc')>self.acc:\n",
    "            self.model.stop_training = True   \n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)       \n",
    "\n",
    "# load data\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(train_data, train_labels), (test_data, test_labels) = fmnist.load_data()\n",
    "            \n",
    "# data normalization and scaling\n",
    "train_data = train_data.reshape(60000, 28, 28, 1)\n",
    "train_data = train_data/255.0\n",
    "test_data = test_data.reshape(10000, 28, 28, 1)\n",
    "test_data = test_data/250.0\n",
    "\n",
    "# model\n",
    "model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# model training\n",
    "callbacks = MyCallback(acc=0.92)\n",
    "#model.fit(train_data, train_labels, epochs=10, callbacks=[callbacks])\n",
    "model.fit(train_data, train_labels, epochs=10)\n",
    "\n",
    "# evaluate model\n",
    "model.evaluate(test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
